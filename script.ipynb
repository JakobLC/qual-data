{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum working examples for universal image segmentation data subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This notebook demonstrates how to handle a subset of 3600 images originating as 200 images per dataset for 18 datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Environment Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To create a conda environment for the repository run the following in a terminal with Anaconda/Miniconda installed:\n",
    "```\n",
    "conda create -n qual-data-env python=3.8.12\n",
    "conda activate qual-data-env\n",
    "conda install -n qual-data-env --file requirements.txt -c conda-forge\n",
    "#pip install git+https://github.com/JakobLC/jlc.git #optional\n",
    "```\n",
    "the jlc package requires torch so a non-torch version with the required functions is also included\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "## Load packages and stuff\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os,sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "import jlc_no_torch as jlc\n",
    "#import jlc # torch dependent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18/18 [00:00<00:00, 201.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset was loaded with 3600 samples from 18 datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Make the dataset and see how large it is\n",
    "\n",
    "dataset = utils.NonTorchSegmentationDataset()\n",
    "print(f\"Dataset was loaded with {len(dataset)} samples from {len(dataset.datasets_info)} datasets\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image from dataset msra with shape (300, 400, 3) and labels {0: 'background', 1: 'foreground'}\n"
     ]
    }
   ],
   "source": [
    "## Load a random image from the dataset and visualize it\n",
    "image,label,info = dataset[np.random.randint(len(dataset))]\n",
    "vis_image = jlc.mask_overlay_smooth(image,label,mask_alpha=0.5,\n",
    "                                    class_names=info[\"idx_to_class\"],\n",
    "                                    show_border=True,\n",
    "                                    fontsize_fixed_image_size=500,\n",
    "                                    border_color=\"black\")\n",
    "plt.imshow(vis_image)\n",
    "print(f\"Loaded image from dataset {info['dataset_name']} with shape {image.shape} and labels {info['idx_to_class']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('np.Size([1000, 2000, 3])',\n",
      " 'np.Size([1000, 2000])',\n",
      " {'class_counts': '<list>len37',\n",
      "  'classes': '<list>len37',\n",
      "  'conditioning': {'same_classes': '<list>len32'},\n",
      "  'dataset_name': 'cityscapes',\n",
      "  'fn': '<str>len114',\n",
      "  'i': 757,\n",
      "  'idx_to_class': '<dict>len37',\n",
      "  'image_path': 'files/757_im.png',\n",
      "  'imshape': [1000, 2000, 3],\n",
      "  'label_path': 'files/757_la.png',\n",
      "  'pretty': False,\n",
      "  'sam': [False, False, False],\n",
      "  'split_idx': 0})\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Inspect the data structure with fancy jlc.shaprint \n",
    "# (\"shape print\") that recursively expands and prints\n",
    "# nested structures, i.e. dicts, lists, tuples, etc. \n",
    "# containing more tuples or arrays or lists or dicts, etc.\n",
    "\n",
    "jlc.shaprint(dataset[np.random.randint(len(dataset))],expand_deepest=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load a random batch and see what it looks like \n",
    "# with a fancy visualization function: jlc.montage\n",
    "\n",
    "images,labels,infos = dataset.get_random_batch(downscale_num_pixels=5e5)\n",
    "vis_images = []\n",
    "for image,label,info in zip(images,labels,infos):\n",
    "    \n",
    "\n",
    "    vis_image = jlc.mask_overlay_smooth(image,label,mask_alpha=0.5,class_names = info[\"idx_to_class\"],fontsize_fixed_image_size=500)\n",
    "    vis_images.append(vis_image)\n",
    "jlc.montage(vis_images,text=[f\"{info['dataset_name']}/{info['i']}\" for info in infos])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diff-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
